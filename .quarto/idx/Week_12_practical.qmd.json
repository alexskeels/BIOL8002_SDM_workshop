{"title":"Species Distribution Modeling in R: Week 12","markdown":{"yaml":{"title":"Species Distribution Modeling in R: Week 12","author":"Alex Skeels","date":"`r Sys.Date()`","format":"html","execute":{"eval":false,"warning":false,"fig-width":6,"fig-height":4}},"headingText":"**Before We Begin**","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, eval=FALSE)\n```\n\n\nTo make sure we're all on the same page and have access to the data, do this at the start of the workshop.\n\n1.  Make sure you have access to the data from GitHub (we downloaded this last week)\n\n2.  Open RStudio\n\n3.  Open Week 12 project file in RStudio\n\n# **Introduction**\n\nToday we are going to continue our journey of modelling the distribution of the Frilled Lizard (*Chlamydosaurus kingii*) using species distribution models (SDM). Last week, we used exclusively geometric models which rely on presence-only data to model range polygons. This week, we will use a class of SDMs that uses presence and absence (or pseudo-absence) data alongside environmental predictor variables to model suitable habitat.\n\n## The Data\n\nWe are going to use the cleaned occurrence records and the associated alpha hull that we worked on last week. You may have slightly different data to your neighbours depending on how you cleaned the data and defined the alpha value for your alpha hulls. That's ok! We will also use bioclimatic data from WorldClim, which are commonly used for SDMs which describe variation in monthly averages of temperature and precipitation, e.g., mean temperature of the warmest quarter or precipitation seasonality. More details on the definition of these variables is [here](https://www.worldclim.org/data/bioclim.html).\n\n------------------------------------------------------------------------\n\n# **1**: Loading and visualising spatial data\n\n### R libraries and data\n\nAgain, lets start off using pacman to install/load necessary packages. This week's new packages are geodata, dismo, gam, and caret.\n\n```{r}\n# use p_load to install or load installed packages\npacman::p_load(terra)  # For raster and vector data\npacman::p_load(ggplot2)  # For plotting\npacman::p_load(geodata)  # For downloading geospatial datasets\npacman::p_load(dismo)  # Species distribution modeling tools\npacman::p_load(gam)  # Generalized additive models\npacman::p_load(caret)  # For model training and evaluation\n```\n\nNow load in the spatial data from last week.\n\n```{r}\n# Load pre-cleaned ALA occurrence data\nocc <- read.csv(\"distribution/frilled_lizard_ALA_cropped.csv\", header = TRUE)\n\n# Load the alpha hull shapefile to define species range\nahull_v <- vect(\"distribution/frilled_lizard_alpha_hull.shp\")\n```\n\n### Bioclimatic Data from WorldClim\n\nThe bioclimatic files are stored as .tif files in the climate folder. You will use the terra package to load these in as a spatRaster object. You are only interested in modelling the distribution in Australia, so you will crop the global raster to the extent of the continent.\n\n```{r}\n# Load all .tif climate files from directory\nbioclim_data <- rast(list.files(\"climate/wc2.1_5m_bio\", full.names = TRUE))\n\n# Crop to Australia region\nbioclim_data <- crop(bioclim_data, ext(110, 155, -45, -9))\n\n# Plot temperature and precipitation\npar(mfrow = c(1, 2))\nplot(bioclim_data[[which(names(bioclim_data)==\"wc2.1_5m_bio_1\")]], main = \"Mean Annual Temp (Bio1)\")\nplot(bioclim_data[[which(names(bioclim_data)==\"wc2.1_5m_bio_12\")]], main = \"Mean Annual Prec (Bio12)\")\n\n```\n\n------------------------------------------------------------------------\n\n\n# **2**: Pseudo-Absence Points\n\nAs mentioned above, environmental model based SDMs require both presence and absence data. For most species, we do not have reliable absence data available so we must use what is known as pseudo-absence (or background) data.\n\nPseudo-absence (PA) data can be sampled in many ways, and how you sample PA will affect your results. A good study on selecting PA is [here](https://doi.org/10.1111/j.2041-210X.2011.00172.x).\n\n```{r}\n# set the random seed - this makes the analysis reproducible\nset.seed(777)\n\n# Sample 10,000 random points from across grid cells in the raster\nbck <- spatSample(bioclim_data[[1]], 10000, method = \"random\", as.points = TRUE, na.rm = TRUE)\n\n# Remove points that fall within the alpha hull \nbck_outside <- erase(bck, ahull_v)\n\n# Remove points outside the alpha hull\nbck_inside <- mask(bck, ahull_v)\n\n# plot inside versus outside\nplot(bioclim_data[[1]], main = \"Mean Annual Temperature\")\nplot(bck_inside , add = TRUE, col = \"blue\", pch = 3)\nplot(bck_outside , add = TRUE, col = \"red\", pch = 3)\n```\n\n### Extract climate from presence / absence records\n\nChoose whether you want to use the approach of inside known range background points or outside known range, or both.\n\n```{r}\n# bck <- bck_inside or bck_outside\n\n# Convert occurrence records to spatial points\nocc_sp <- vect(occ, geom = c(\"X\", \"Y\"))\n\n# Visualise presence and background\nplot(bioclim_data[[1]], main = \"Mean Annual Temperature\")\nplot(bck , add = TRUE, col = \"blue\", pch = 3)\nplot(occ_sp , add = TRUE, pch = 20, col = \"red\")\n\n# Combine presence and background points\npres_abs <- vect(c(occ_sp, bck))  # bck_sp now assumed as bck\n\n# Extract climate values\nbioclim_pres_abs <- extract(bioclim_data, pres_abs)\n\n# Add presence/absence label\nbioclim_pres_abs$presence <- c(rep(1, nrow(occ)), rep(0, nrow(bck)))\nbioclim_pres_abs <- na.omit(bioclim_pres_abs)\n\n# plot the density of points\nggplot(bioclim_pres_abs, aes(x=wc2.1_5m_bio_1, fill=as.factor(presence)))+\n  geom_density(alpha=0.7)+\n  theme_classic()\n\n```\n\n#### Task 1\n\nPlot different the distribution of a couple of different tempereature and precipitation bioclim variables and make a note of how the presence and absence points occupy different parts of the climate space. Repeat for the two alternative kinds of background sampling methods.\n\n-   **Question:** What is the main difference between sampling background points inside or outside the known distribution? How might this affect an SDM?\n\nYou can see that defining the background points will change the degree of contrast between presence and absence environments. Before moving on, select which background points you will use.\n\n------------------------------------------------------------------------\n\n# **3**: Fit and evaluate SDMs\n\nNow that we have presence and pseudo-absence data together, and the environmental data sampled at each site, we can move onto the modelling part of the prac. We will be fitting two kinds of statistical models, a generalised linear model (GLM) and a generalised additive model (GAM). GLMs model linear association between environmental predictors and the response (presence/absence), whereas GAMs can model non linear relationships using smoothing functions. Fitting SDMs is a computationally costly procedure, usually done at high spatial resolution, with many environmental varaibles, and using a variety of complex statsitical and machine learning models.\n\nHere, we are performing a simplified workflow to get an understanding of the fundamentals, but it is important to note that these models are by no means a \"perfect\" approach.\n\nSelecting environmental variables is an important step that requires a lot of thought. The predictors should be selected based on some ecological knowledge of the organism and not include variables that are irrelavant to the organisms. Here we are focusing only on climate variables. Both the GAM and GLM approaches don't work particularly well with colinear predictors (i.e. highly correlated environmental variables). So the first step is to select the uncorrelated variables.\n\n```{r}\n# Check variable collinearity\ncorrelation_matrix <- cor(bioclim_pres_abs[,2:20])\ncorrelated <- findCorrelation(correlation_matrix)\nnames_correlated <- colnames(bioclim_pres_abs[,2:20])[correlated]\n\n# Remove correlated variables\nbioclim_pres_abs_uncor <- bioclim_pres_abs[, which(!colnames(bioclim_pres_abs) %in% names_correlated)]\n\n# get predictor names of uncorrelated variables\npredictor_vars <- colnames(bioclim_pres_abs_uncor)[grep(\"wc2.1_\", colnames(bioclim_pres_abs_uncor))]\n\n# check which ones were retained\nprint(predictor_vars)\n```\n\nNow that we have a set of uncorrelated predictor variables, now we can define our models and fit them. Here the spline values is deined as k = 4, for more complex curves you can increase this value, or for more simple curves you can reduce this.\n\n```{r}\n# establish model formulas for GLM and GAM\nformula_glm <- formula(paste0(\"presence ~ \", paste0(predictor_vars, collapse = \" + \")))\nformula_gam <- formula(paste0(\"presence ~ \", paste0(\"s(\", predictor_vars,\",4)\", collapse = \" + \")))\n\n# look at these - how do they differ?\nprint(formula_glm)\nprint(formula_gam)\n```\n\nNow fit the models and look at the model summaries.\n\n```{r}\n# Fit GLM (logistic regression)\nglm_sdm <- glm(formula_glm, data=bioclim_pres_abs_uncor, family=binomial(link = \"logit\"))\nsummary(glm_sdm)\n\n# Fit GAM\ngam_sdm <- gam(formula_gam,data=bioclim_pres_abs_uncor, family=binomial(link = \"logit\"))\nsummary(gam_sdm)\n```\n\n#### Task 2\n\nWhich model is better? The model summaries contain a lot of information to help us decide which of the models is a better fit to our data. Akaike Information Criteria (AIC) is one measure of model fit with lower values meaning a better fit. Another fit is the explained deviance (D-squared), defined as the (null deviance - residual deviance)/null deviance. Look at the model summaries and answer the following questions.\n\n-   **Question:** Are the same variables considered significant in both models? If no, why do you think?\n-   **Question:** Which model has a lower AIC? and which model has a lower explained deviance?\n\n### Evaulate models\n\nD-squared and AIC tell us how well our models fit the data, but they don't necessarily tell us how well the models predict new or unseen data. To evaluate predictive performance, we need to test how well our models distinguish suitable from unsuitable environments.\n\nA common way to do this is by plotting a Receiver Operating Characteristic (ROC) curve and calculating the Area Under the Curve (AUC). AUC measures how well the model separates presences from absences across a range of thresholds. Values closer to 1 indicate better discrimination, while values around 0.5 suggest the model performs no better than random guessing.\n\n```{r}\n# Split presence and background\np <- bioclim_pres_abs[which(bioclim_pres_abs$presence==1),]\na <- bioclim_pres_abs[which(bioclim_pres_abs$presence==0),]\n\n# Evaluate using AUC, ROC, Kappa\nglm_eval <- evaluate(p=p,  a=a, model=glm_sdm, type='response')\ngam_eval <- evaluate(p=p, a=a, model=gam_sdm, type='response')\n\n# Plot ROC and Kappa\npar(mfrow=c(1,2))\nplot(glm_eval, \"ROC\")\nplot(gam_eval, \"ROC\")\n```\n\n-   **Question:** How did your models perform? \n\n\nBut how stable are these AUC values? and how well does the model perform when evaluating the model on unseen data? To explore this, we’ll use k-fold cross-validation. This technique splits the data into k subsets (or \"folds\"), trains the model on k – 1 of them, and tests it on the remaining fold. This is repeated k times, giving us a better estimate of how variable model performance is across different subsets of the data.\n\n```{r}\n# Define number of folds\nK <- 5\n\n# randomly assign rows of data to a fold\nk_fold <- kfold(bioclim_pres_abs, k=K)\n\n# set up a table to store results\nauc_df <- data.frame(k=1:5, glm_AUC=NA, gam_AUC=NA)\n\n# loop over each fold\nfor(k in 1:K){\n  \n  # separate folds into train and test data\n  train <- bioclim_pres_abs[k_fold!=k,]\n  test <- bioclim_pres_abs[k_fold==k,]\n  \n  # update model using new train subset\n  modtmp_glm <- update(glm_sdm, data = train)\n  modtmp_gam <- update(gam_sdm, data = train)\n\n  # evaluate model on test subset\n  glm_eval_tmp <- evaluate(p=test[which(test$presence==1),], a=test[which(test$presence==0),], model=modtmp_glm, type='response')\n  gam_eval_tmp <- evaluate(p=test[which(test$presence==1),], a=test[which(test$presence==0),], model=modtmp_gam, type='response')\n\n  # store the AUC values\n  auc_df[k, \"glm_AUC\"] <- glm_eval_tmp@auc\n  auc_df[k, \"gam_AUC\"] <- gam_eval_tmp@auc\n}\n\n# take a look at change in AUC on different folds\nprint(auc_df)\n```\n\n-   **Question:** Are the AUC scores in K-fold very different from scores from the full model? What does this say about model transferability on new data?\n\n<br> <br>\n\n------------------------------------------------------------------------\n\n<br> <br>\n\n# **4**: SDM Predictions\n\nOnce we've trained and evaluated our models, the next step is to visualize where the species is likely to occur based on the environmental predictors. This is done by projecting the model predictions across the landscape, giving us a continuous surface of habitat suitability values between 0 and 1.\n\n```{r}\n# Predict to spatial layers\nglm_prediction <- predict(bioclim_data, glm_sdm, type=\"response\")\ngam_prediction <- predict(bioclim_data, gam_sdm, type=\"response\")\n\n# Plot model predictions\npar(mfrow=c(1,2))\nplot(glm_prediction, main=\"glm\")\nplot(gam_prediction, main=\"gam\")\n\n```\n#### Thresholding Habitat Suitability\n\nTo translate these continuous predictions into a map of presence vs. absence, we need to apply a threshold. One common approach is to use the threshold that maximizes the Kappa statistic, which balances both sensitivity (true positives) and specificity (true negatives).\n\nAfter thresholding, we can create binary maps showing predicted suitable (1) and unsuitable (0) areas. These maps help us estimate the species’ potential distribution and visually assess model differences.\n\n```{r}\n# Get threshold using maximum kappa\nglm_threshold_val <- threshold(glm_eval, stat = \"kappa\")\ngam_threshold_val <- threshold(gam_eval, stat = \"kappa\")\n\n# Apply threshold to get binary maps\npar(mfrow=c(1,2))\nplot(glm_prediction > glm_threshold_val, main=\"GLM binary\")\nplot(gam_prediction > gam_threshold_val, main=\"GAM binary\")\n```\n#### Putting it together\n\nFinally, we’ll overlay our species occurrence records and alpha hull boundary on the binary prediction map. This lets us compare the model-based distribution with the observed occurrences, giving us a sense of how well the model aligns with known data.\n\n```{r}\n# Plot with occurrence records\npar(mfrow=c(1,2))\nplot(gam_prediction > gam_threshold_val, main=\"GAM binary\")\nplot(occ_sp, add=T, pch=1)\nplot(ahull_v, add=T)\n\nplot(glm_prediction > glm_threshold_val, main=\"GAM binary\")\nplot(occ_sp, add=T, pch=1)\nplot(ahull_v, add=T)\n\n```\n-   **Question:** Which method provides a better representation of the species range?\n\n-   **Question:** What might we do to improve our SDM models?\n\n# Fin!","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, eval=FALSE)\n```\n\n# **Before We Begin**\n\nTo make sure we're all on the same page and have access to the data, do this at the start of the workshop.\n\n1.  Make sure you have access to the data from GitHub (we downloaded this last week)\n\n2.  Open RStudio\n\n3.  Open Week 12 project file in RStudio\n\n# **Introduction**\n\nToday we are going to continue our journey of modelling the distribution of the Frilled Lizard (*Chlamydosaurus kingii*) using species distribution models (SDM). Last week, we used exclusively geometric models which rely on presence-only data to model range polygons. This week, we will use a class of SDMs that uses presence and absence (or pseudo-absence) data alongside environmental predictor variables to model suitable habitat.\n\n## The Data\n\nWe are going to use the cleaned occurrence records and the associated alpha hull that we worked on last week. You may have slightly different data to your neighbours depending on how you cleaned the data and defined the alpha value for your alpha hulls. That's ok! We will also use bioclimatic data from WorldClim, which are commonly used for SDMs which describe variation in monthly averages of temperature and precipitation, e.g., mean temperature of the warmest quarter or precipitation seasonality. More details on the definition of these variables is [here](https://www.worldclim.org/data/bioclim.html).\n\n------------------------------------------------------------------------\n\n# **1**: Loading and visualising spatial data\n\n### R libraries and data\n\nAgain, lets start off using pacman to install/load necessary packages. This week's new packages are geodata, dismo, gam, and caret.\n\n```{r}\n# use p_load to install or load installed packages\npacman::p_load(terra)  # For raster and vector data\npacman::p_load(ggplot2)  # For plotting\npacman::p_load(geodata)  # For downloading geospatial datasets\npacman::p_load(dismo)  # Species distribution modeling tools\npacman::p_load(gam)  # Generalized additive models\npacman::p_load(caret)  # For model training and evaluation\n```\n\nNow load in the spatial data from last week.\n\n```{r}\n# Load pre-cleaned ALA occurrence data\nocc <- read.csv(\"distribution/frilled_lizard_ALA_cropped.csv\", header = TRUE)\n\n# Load the alpha hull shapefile to define species range\nahull_v <- vect(\"distribution/frilled_lizard_alpha_hull.shp\")\n```\n\n### Bioclimatic Data from WorldClim\n\nThe bioclimatic files are stored as .tif files in the climate folder. You will use the terra package to load these in as a spatRaster object. You are only interested in modelling the distribution in Australia, so you will crop the global raster to the extent of the continent.\n\n```{r}\n# Load all .tif climate files from directory\nbioclim_data <- rast(list.files(\"climate/wc2.1_5m_bio\", full.names = TRUE))\n\n# Crop to Australia region\nbioclim_data <- crop(bioclim_data, ext(110, 155, -45, -9))\n\n# Plot temperature and precipitation\npar(mfrow = c(1, 2))\nplot(bioclim_data[[which(names(bioclim_data)==\"wc2.1_5m_bio_1\")]], main = \"Mean Annual Temp (Bio1)\")\nplot(bioclim_data[[which(names(bioclim_data)==\"wc2.1_5m_bio_12\")]], main = \"Mean Annual Prec (Bio12)\")\n\n```\n\n------------------------------------------------------------------------\n\n\n# **2**: Pseudo-Absence Points\n\nAs mentioned above, environmental model based SDMs require both presence and absence data. For most species, we do not have reliable absence data available so we must use what is known as pseudo-absence (or background) data.\n\nPseudo-absence (PA) data can be sampled in many ways, and how you sample PA will affect your results. A good study on selecting PA is [here](https://doi.org/10.1111/j.2041-210X.2011.00172.x).\n\n```{r}\n# set the random seed - this makes the analysis reproducible\nset.seed(777)\n\n# Sample 10,000 random points from across grid cells in the raster\nbck <- spatSample(bioclim_data[[1]], 10000, method = \"random\", as.points = TRUE, na.rm = TRUE)\n\n# Remove points that fall within the alpha hull \nbck_outside <- erase(bck, ahull_v)\n\n# Remove points outside the alpha hull\nbck_inside <- mask(bck, ahull_v)\n\n# plot inside versus outside\nplot(bioclim_data[[1]], main = \"Mean Annual Temperature\")\nplot(bck_inside , add = TRUE, col = \"blue\", pch = 3)\nplot(bck_outside , add = TRUE, col = \"red\", pch = 3)\n```\n\n### Extract climate from presence / absence records\n\nChoose whether you want to use the approach of inside known range background points or outside known range, or both.\n\n```{r}\n# bck <- bck_inside or bck_outside\n\n# Convert occurrence records to spatial points\nocc_sp <- vect(occ, geom = c(\"X\", \"Y\"))\n\n# Visualise presence and background\nplot(bioclim_data[[1]], main = \"Mean Annual Temperature\")\nplot(bck , add = TRUE, col = \"blue\", pch = 3)\nplot(occ_sp , add = TRUE, pch = 20, col = \"red\")\n\n# Combine presence and background points\npres_abs <- vect(c(occ_sp, bck))  # bck_sp now assumed as bck\n\n# Extract climate values\nbioclim_pres_abs <- extract(bioclim_data, pres_abs)\n\n# Add presence/absence label\nbioclim_pres_abs$presence <- c(rep(1, nrow(occ)), rep(0, nrow(bck)))\nbioclim_pres_abs <- na.omit(bioclim_pres_abs)\n\n# plot the density of points\nggplot(bioclim_pres_abs, aes(x=wc2.1_5m_bio_1, fill=as.factor(presence)))+\n  geom_density(alpha=0.7)+\n  theme_classic()\n\n```\n\n#### Task 1\n\nPlot different the distribution of a couple of different tempereature and precipitation bioclim variables and make a note of how the presence and absence points occupy different parts of the climate space. Repeat for the two alternative kinds of background sampling methods.\n\n-   **Question:** What is the main difference between sampling background points inside or outside the known distribution? How might this affect an SDM?\n\nYou can see that defining the background points will change the degree of contrast between presence and absence environments. Before moving on, select which background points you will use.\n\n------------------------------------------------------------------------\n\n# **3**: Fit and evaluate SDMs\n\nNow that we have presence and pseudo-absence data together, and the environmental data sampled at each site, we can move onto the modelling part of the prac. We will be fitting two kinds of statistical models, a generalised linear model (GLM) and a generalised additive model (GAM). GLMs model linear association between environmental predictors and the response (presence/absence), whereas GAMs can model non linear relationships using smoothing functions. Fitting SDMs is a computationally costly procedure, usually done at high spatial resolution, with many environmental varaibles, and using a variety of complex statsitical and machine learning models.\n\nHere, we are performing a simplified workflow to get an understanding of the fundamentals, but it is important to note that these models are by no means a \"perfect\" approach.\n\nSelecting environmental variables is an important step that requires a lot of thought. The predictors should be selected based on some ecological knowledge of the organism and not include variables that are irrelavant to the organisms. Here we are focusing only on climate variables. Both the GAM and GLM approaches don't work particularly well with colinear predictors (i.e. highly correlated environmental variables). So the first step is to select the uncorrelated variables.\n\n```{r}\n# Check variable collinearity\ncorrelation_matrix <- cor(bioclim_pres_abs[,2:20])\ncorrelated <- findCorrelation(correlation_matrix)\nnames_correlated <- colnames(bioclim_pres_abs[,2:20])[correlated]\n\n# Remove correlated variables\nbioclim_pres_abs_uncor <- bioclim_pres_abs[, which(!colnames(bioclim_pres_abs) %in% names_correlated)]\n\n# get predictor names of uncorrelated variables\npredictor_vars <- colnames(bioclim_pres_abs_uncor)[grep(\"wc2.1_\", colnames(bioclim_pres_abs_uncor))]\n\n# check which ones were retained\nprint(predictor_vars)\n```\n\nNow that we have a set of uncorrelated predictor variables, now we can define our models and fit them. Here the spline values is deined as k = 4, for more complex curves you can increase this value, or for more simple curves you can reduce this.\n\n```{r}\n# establish model formulas for GLM and GAM\nformula_glm <- formula(paste0(\"presence ~ \", paste0(predictor_vars, collapse = \" + \")))\nformula_gam <- formula(paste0(\"presence ~ \", paste0(\"s(\", predictor_vars,\",4)\", collapse = \" + \")))\n\n# look at these - how do they differ?\nprint(formula_glm)\nprint(formula_gam)\n```\n\nNow fit the models and look at the model summaries.\n\n```{r}\n# Fit GLM (logistic regression)\nglm_sdm <- glm(formula_glm, data=bioclim_pres_abs_uncor, family=binomial(link = \"logit\"))\nsummary(glm_sdm)\n\n# Fit GAM\ngam_sdm <- gam(formula_gam,data=bioclim_pres_abs_uncor, family=binomial(link = \"logit\"))\nsummary(gam_sdm)\n```\n\n#### Task 2\n\nWhich model is better? The model summaries contain a lot of information to help us decide which of the models is a better fit to our data. Akaike Information Criteria (AIC) is one measure of model fit with lower values meaning a better fit. Another fit is the explained deviance (D-squared), defined as the (null deviance - residual deviance)/null deviance. Look at the model summaries and answer the following questions.\n\n-   **Question:** Are the same variables considered significant in both models? If no, why do you think?\n-   **Question:** Which model has a lower AIC? and which model has a lower explained deviance?\n\n### Evaulate models\n\nD-squared and AIC tell us how well our models fit the data, but they don't necessarily tell us how well the models predict new or unseen data. To evaluate predictive performance, we need to test how well our models distinguish suitable from unsuitable environments.\n\nA common way to do this is by plotting a Receiver Operating Characteristic (ROC) curve and calculating the Area Under the Curve (AUC). AUC measures how well the model separates presences from absences across a range of thresholds. Values closer to 1 indicate better discrimination, while values around 0.5 suggest the model performs no better than random guessing.\n\n```{r}\n# Split presence and background\np <- bioclim_pres_abs[which(bioclim_pres_abs$presence==1),]\na <- bioclim_pres_abs[which(bioclim_pres_abs$presence==0),]\n\n# Evaluate using AUC, ROC, Kappa\nglm_eval <- evaluate(p=p,  a=a, model=glm_sdm, type='response')\ngam_eval <- evaluate(p=p, a=a, model=gam_sdm, type='response')\n\n# Plot ROC and Kappa\npar(mfrow=c(1,2))\nplot(glm_eval, \"ROC\")\nplot(gam_eval, \"ROC\")\n```\n\n-   **Question:** How did your models perform? \n\n\nBut how stable are these AUC values? and how well does the model perform when evaluating the model on unseen data? To explore this, we’ll use k-fold cross-validation. This technique splits the data into k subsets (or \"folds\"), trains the model on k – 1 of them, and tests it on the remaining fold. This is repeated k times, giving us a better estimate of how variable model performance is across different subsets of the data.\n\n```{r}\n# Define number of folds\nK <- 5\n\n# randomly assign rows of data to a fold\nk_fold <- kfold(bioclim_pres_abs, k=K)\n\n# set up a table to store results\nauc_df <- data.frame(k=1:5, glm_AUC=NA, gam_AUC=NA)\n\n# loop over each fold\nfor(k in 1:K){\n  \n  # separate folds into train and test data\n  train <- bioclim_pres_abs[k_fold!=k,]\n  test <- bioclim_pres_abs[k_fold==k,]\n  \n  # update model using new train subset\n  modtmp_glm <- update(glm_sdm, data = train)\n  modtmp_gam <- update(gam_sdm, data = train)\n\n  # evaluate model on test subset\n  glm_eval_tmp <- evaluate(p=test[which(test$presence==1),], a=test[which(test$presence==0),], model=modtmp_glm, type='response')\n  gam_eval_tmp <- evaluate(p=test[which(test$presence==1),], a=test[which(test$presence==0),], model=modtmp_gam, type='response')\n\n  # store the AUC values\n  auc_df[k, \"glm_AUC\"] <- glm_eval_tmp@auc\n  auc_df[k, \"gam_AUC\"] <- gam_eval_tmp@auc\n}\n\n# take a look at change in AUC on different folds\nprint(auc_df)\n```\n\n-   **Question:** Are the AUC scores in K-fold very different from scores from the full model? What does this say about model transferability on new data?\n\n<br> <br>\n\n------------------------------------------------------------------------\n\n<br> <br>\n\n# **4**: SDM Predictions\n\nOnce we've trained and evaluated our models, the next step is to visualize where the species is likely to occur based on the environmental predictors. This is done by projecting the model predictions across the landscape, giving us a continuous surface of habitat suitability values between 0 and 1.\n\n```{r}\n# Predict to spatial layers\nglm_prediction <- predict(bioclim_data, glm_sdm, type=\"response\")\ngam_prediction <- predict(bioclim_data, gam_sdm, type=\"response\")\n\n# Plot model predictions\npar(mfrow=c(1,2))\nplot(glm_prediction, main=\"glm\")\nplot(gam_prediction, main=\"gam\")\n\n```\n#### Thresholding Habitat Suitability\n\nTo translate these continuous predictions into a map of presence vs. absence, we need to apply a threshold. One common approach is to use the threshold that maximizes the Kappa statistic, which balances both sensitivity (true positives) and specificity (true negatives).\n\nAfter thresholding, we can create binary maps showing predicted suitable (1) and unsuitable (0) areas. These maps help us estimate the species’ potential distribution and visually assess model differences.\n\n```{r}\n# Get threshold using maximum kappa\nglm_threshold_val <- threshold(glm_eval, stat = \"kappa\")\ngam_threshold_val <- threshold(gam_eval, stat = \"kappa\")\n\n# Apply threshold to get binary maps\npar(mfrow=c(1,2))\nplot(glm_prediction > glm_threshold_val, main=\"GLM binary\")\nplot(gam_prediction > gam_threshold_val, main=\"GAM binary\")\n```\n#### Putting it together\n\nFinally, we’ll overlay our species occurrence records and alpha hull boundary on the binary prediction map. This lets us compare the model-based distribution with the observed occurrences, giving us a sense of how well the model aligns with known data.\n\n```{r}\n# Plot with occurrence records\npar(mfrow=c(1,2))\nplot(gam_prediction > gam_threshold_val, main=\"GAM binary\")\nplot(occ_sp, add=T, pch=1)\nplot(ahull_v, add=T)\n\nplot(glm_prediction > glm_threshold_val, main=\"GAM binary\")\nplot(occ_sp, add=T, pch=1)\nplot(ahull_v, add=T)\n\n```\n-   **Question:** Which method provides a better representation of the species range?\n\n-   **Question:** What might we do to improve our SDM models?\n\n# Fin!"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":6,"fig-height":4,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"Week_12_practical.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.551","editor":"visual","title":"Species Distribution Modeling in R: Week 12","author":"Alex Skeels","date":"`r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}