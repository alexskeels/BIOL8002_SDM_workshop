---
title: "Week 12 Prac: Climate data and statistical SDMs in R"
author: "Alex Skeels"
date: "`r Sys.Date()`"
format: html
execute:
  eval: false
  warning: false
  fig-width: 6    # inches
  fig-height: 4   # inches
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
```

# **Before We Begin**

To make sure we're all on the same page and have access to the data, do this at the start of the workshop.

1.  Make sure you have access to the data from GitHub (we downloaded this last week)

2.  Open RStudio

3.  Open project file in RStudio "SDM_practical.RProj"

# **Introduction**

Today we are going to continue our journey of modelling the distribution of the Frilled Lizard (*Chlamydosaurus kingii*) using species distribution models (SDM). Last week, we used exclusively geometric models which rely on presence-only data to model range polygons. This week, we will use a class of SDMs that uses presence and absence (or pseudo-absence) data alongside environmental predictor variables to model suitable habitat.

## The Data

We are going to use the cleaned occurrence records and the associated alpha hull that we worked on last week. You may have slightly different data to your neighbours depending on how you cleaned the data and defined the alpha value for your alpha hulls. That's ok! We will also use bioclimatic data from WorldClim, which are commonly used for SDMs which describe variation in monthly averages of temperature and precipitation, e.g., mean temperature of the warmest quarter or precipitation seasonality. More details on the definition of these variables is [here](https://www.worldclim.org/data/bioclim.html).

------------------------------------------------------------------------

# **1**: Loading and visualising spatial data

### R libraries and data

Again, lets start off using pacman to install/load necessary packages. This week's new packages are geodata, dismo, gam, and caret.

```{r}
# use p_load to install or load installed packages
pacman::p_load(terra)  # For raster and vector data
pacman::p_load(ggplot2)  # For plotting
pacman::p_load(geodata)  # For downloading geospatial datasets
pacman::p_load(dismo)  # Species distribution modeling tools
pacman::p_load(gam)  # Generalized additive models
pacman::p_load(caret)  # For model training and evaluation
```

Now load in the spatial data from last week.

```{r}
# Load pre-cleaned ALA occurrence data
occ <- read.csv("distribution/frilled_lizard_ALA_cropped.csv", header = TRUE)

# Load the alpha hull shapefile to define species range
ahull_v <- vect("distribution/frilled_lizard_alpha_hull.shp")
```

### Bioclimatic Data from WorldClim

The bioclimatic files are stored as .tif files in the climate folder. You will use the terra package to load these in as a spatRaster object. You are only interested in modelling the distribution in Australia, so you will crop the global raster to the extent of the continent.

```{r}
# Load all .tif climate files from directory
bioclim_data <- rast(list.files("climate/wc2.1_5m_bio", full.names = TRUE))

# Crop to Australia region
bioclim_data <- crop(bioclim_data, ext(110, 155, -45, -9))

# Plot temperature and precipitation
par(mfrow = c(1, 2))
plot(bioclim_data[[which(names(bioclim_data)=="wc2.1_5m_bio_1")]], main = "Mean Annual Temp (Bio1)")
plot(bioclim_data[[which(names(bioclim_data)=="wc2.1_5m_bio_12")]], main = "Mean Annual Prec (Bio12)")

```

------------------------------------------------------------------------


# **2**: Pseudo-Absence Points

As mentioned above, environmental model based SDMs require both presence and absence data. For most species, we do not have reliable absence data available so we must use what is known as pseudo-absence (or background) data.

Pseudo-absence (PA) data can be sampled in many ways, and how you sample PA will affect your results. A good study on selecting PA is [here](https://doi.org/10.1111/j.2041-210X.2011.00172.x).

```{r}
# set the random seed - this makes the analysis reproducible
set.seed(777)

# Sample 10,000 random points from across grid cells in the raster
bck <- spatSample(bioclim_data[[1]], 10000, method = "random", as.points = TRUE, na.rm = TRUE)

# Remove points that fall within the alpha hull 
bck_outside <- erase(bck, ahull_v)

# Remove points outside the alpha hull
bck_inside <- mask(bck, ahull_v)

# plot inside versus outside
plot(bioclim_data[[1]], main = "Mean Annual Temperature")
plot(bck_inside , add = TRUE, col = "blue", pch = 3)
plot(bck_outside , add = TRUE, col = "red", pch = 3)
```

### Extract climate from presence / absence records

Choose whether you want to use the approach of inside known range background points or outside known range, or both.

```{r}
# bck <- bck_inside or bck_outside

# Convert occurrence records to spatial points
occ_sp <- vect(occ, geom = c("X", "Y"))

# Visualise presence and background
plot(bioclim_data[[1]], main = "Mean Annual Temperature")
plot(bck , add = TRUE, col = "blue", pch = 3)
plot(occ_sp , add = TRUE, pch = 20, col = "red")

# Combine presence and background points
pres_abs <- vect(c(occ_sp, bck))  # bck_sp now assumed as bck

# Extract climate values
bioclim_pres_abs <- extract(bioclim_data, pres_abs)

# Add presence/absence label
bioclim_pres_abs$presence <- c(rep(1, nrow(occ)), rep(0, nrow(bck)))
bioclim_pres_abs <- na.omit(bioclim_pres_abs)

# plot the density of points
ggplot(bioclim_pres_abs, aes(x=wc2.1_5m_bio_1, fill=as.factor(presence)))+
  geom_density(alpha=0.7)+
  theme_classic()

```

#### Task 1

Plot different the distribution of a couple of different tempereature and precipitation bioclim variables and make a note of how the presence and absence points occupy different parts of the climate space. Repeat for the two alternative kinds of background sampling methods.

-   **Question:** What is the main difference between sampling background points inside or outside the known distribution? How might this affect an SDM?

You can see that defining the background points will change the degree of contrast between presence and absence environments. Before moving on, select which background points you will use.

------------------------------------------------------------------------

# **3**: Fit and evaluate SDMs

Now that we have presence and pseudo-absence data together, and the environmental data sampled at each site, we can move onto the modelling part of the prac. We will be fitting two kinds of statistical models, a generalised linear model (GLM) and a generalised additive model (GAM). GLMs model linear association between environmental predictors and the response (presence/absence), whereas GAMs can model non linear relationships using smoothing functions. Fitting SDMs is a computationally costly procedure, usually done at high spatial resolution, with many environmental varaibles, and using a variety of complex statsitical and machine learning models.

Here, we are performing a simplified workflow to get an understanding of the fundamentals, but it is important to note that these models are by no means a "perfect" approach.

Selecting environmental variables is an important step that requires a lot of thought. The predictors should be selected based on some ecological knowledge of the organism and not include variables that are irrelavant to the organisms. Here we are focusing only on climate variables. Both the GAM and GLM approaches don't work particularly well with colinear predictors (i.e. highly correlated environmental variables). So the first step is to select the uncorrelated variables.

```{r}
# Check variable collinearity
correlation_matrix <- cor(bioclim_pres_abs[,2:20])
correlated <- findCorrelation(correlation_matrix)
names_correlated <- colnames(bioclim_pres_abs[,2:20])[correlated]

# Remove correlated variables
bioclim_pres_abs_uncor <- bioclim_pres_abs[, which(!colnames(bioclim_pres_abs) %in% names_correlated)]

# get predictor names of uncorrelated variables
predictor_vars <- colnames(bioclim_pres_abs_uncor)[grep("wc2.1_", colnames(bioclim_pres_abs_uncor))]

# check which ones were retained
print(predictor_vars)
```

Now that we have a set of uncorrelated predictor variables, now we can define our models and fit them. Here the spline values is deined as k = 4, for more complex curves you can increase this value, or for more simple curves you can reduce this.

```{r}
# establish model formulas for GLM and GAM
formula_glm <- formula(paste0("presence ~ ", paste0(predictor_vars, collapse = " + ")))
formula_gam <- formula(paste0("presence ~ ", paste0("s(", predictor_vars,",4)", collapse = " + ")))

# look at these - how do they differ?
print(formula_glm)
print(formula_gam)
```

Now fit the models and look at the model summaries.

```{r}
# Fit GLM (logistic regression)
glm_sdm <- glm(formula_glm, data=bioclim_pres_abs_uncor, family=binomial(link = "logit"))
summary(glm_sdm)

# Fit GAM
gam_sdm <- gam(formula_gam,data=bioclim_pres_abs_uncor, family=binomial(link = "logit"))
summary(gam_sdm)
```

#### Task 2

Which model is better? The model summaries contain a lot of information to help us decide which of the models is a better fit to our data. Akaike Information Criteria (AIC) is one measure of model fit with lower values meaning a better fit. Another fit is the explained deviance (D-squared), defined as the (null deviance - residual deviance)/null deviance. Look at the model summaries and answer the following questions.

-   **Question:** Are the same variables considered significant in both models? If no, why do you think?
-   **Question:** Which model has a lower AIC? and which model has a lower explained deviance?

### Evaulate models

D-squared and AIC tell us how well our models fit the data, but they don't necessarily tell us how well the models predict new or unseen data. To evaluate predictive performance, we need to test how well our models distinguish suitable from unsuitable environments.

A common way to do this is by plotting a Receiver Operating Characteristic (ROC) curve and calculating the Area Under the Curve (AUC). AUC measures how well the model separates presences from absences across a range of thresholds. Values closer to 1 indicate better discrimination, while values around 0.5 suggest the model performs no better than random guessing.

```{r}
# Split presence and background
p <- bioclim_pres_abs[which(bioclim_pres_abs$presence==1),]
a <- bioclim_pres_abs[which(bioclim_pres_abs$presence==0),]

# Evaluate using AUC, ROC, Kappa
glm_eval <- evaluate(p=p,  a=a, model=glm_sdm, type='response')
gam_eval <- evaluate(p=p, a=a, model=gam_sdm, type='response')

# Plot ROC and Kappa
par(mfrow=c(1,2))
plot(glm_eval, "ROC")
plot(gam_eval, "ROC")
```

-   **Question:** How did your models perform? 


But how stable are these AUC values? and how well does the model perform when evaluating the model on unseen data? To explore this, we’ll use k-fold cross-validation. This technique splits the data into k subsets (or "folds"), trains the model on k – 1 of them, and tests it on the remaining fold. This is repeated k times, giving us a better estimate of how variable model performance is across different subsets of the data.

```{r}
# Define number of folds
K <- 5

# randomly assign rows of data to a fold
k_fold <- kfold(bioclim_pres_abs, k=K)

# set up a table to store results
auc_df <- data.frame(k=1:5, glm_AUC=NA, gam_AUC=NA)

# loop over each fold
for(k in 1:K){
  
  # separate folds into train and test data
  train <- bioclim_pres_abs[k_fold!=k,]
  test <- bioclim_pres_abs[k_fold==k,]
  
  # update model using new train subset
  modtmp_glm <- update(glm_sdm, data = train)
  modtmp_gam <- update(gam_sdm, data = train)

  # evaluate model on test subset
  glm_eval_tmp <- evaluate(p=test[which(test$presence==1),], a=test[which(test$presence==0),], model=modtmp_glm, type='response')
  gam_eval_tmp <- evaluate(p=test[which(test$presence==1),], a=test[which(test$presence==0),], model=modtmp_gam, type='response')

  # store the AUC values
  auc_df[k, "glm_AUC"] <- glm_eval_tmp@auc
  auc_df[k, "gam_AUC"] <- gam_eval_tmp@auc
}

# take a look at change in AUC on different folds
print(auc_df)
```

-   **Question:** Are the AUC scores in K-fold very different from scores from the full model? What does this say about model transferability on new data?

<br> <br>

------------------------------------------------------------------------

<br> <br>

# **4**: SDM Predictions

Once we've trained and evaluated our models, the next step is to visualize where the species is likely to occur based on the environmental predictors. This is done by projecting the model predictions across the landscape, giving us a continuous surface of habitat suitability values between 0 and 1.

```{r}
# Predict to spatial layers
glm_prediction <- predict(bioclim_data, glm_sdm, type="response")
gam_prediction <- predict(bioclim_data, gam_sdm, type="response")

# Plot model predictions
par(mfrow=c(1,2))
plot(glm_prediction, main="glm")
plot(gam_prediction, main="gam")

```
#### Thresholding Habitat Suitability

To translate these continuous predictions into a map of presence vs. absence, we need to apply a threshold. One common approach is to use the threshold that maximizes the Kappa statistic, which balances both sensitivity (true positives) and specificity (true negatives).

After thresholding, we can create binary maps showing predicted suitable (1) and unsuitable (0) areas. These maps help us estimate the species’ potential distribution and visually assess model differences.

```{r}
# Get threshold using maximum kappa
glm_threshold_val <- threshold(glm_eval, stat = "kappa")
gam_threshold_val <- threshold(gam_eval, stat = "kappa")

# Apply threshold to get binary maps
par(mfrow=c(1,2))
plot(glm_prediction > glm_threshold_val, main="GLM binary")
plot(gam_prediction > gam_threshold_val, main="GAM binary")
```
#### Putting it together

Finally, we’ll overlay our species occurrence records and alpha hull boundary on the binary prediction map. This lets us compare the model-based distribution with the observed occurrences, giving us a sense of how well the model aligns with known data.

```{r}
# Plot with occurrence records
par(mfrow=c(1,2))
plot(gam_prediction > gam_threshold_val, main="GAM binary")
plot(occ_sp, add=T, pch=1)
plot(ahull_v, add=T)

plot(glm_prediction > glm_threshold_val, main="GAM binary")
plot(occ_sp, add=T, pch=1)
plot(ahull_v, add=T)

```
-   **Question:** Which method provides a better representation of the species range?

-   **Question:** What might we do to improve our SDM models?

# Fin!